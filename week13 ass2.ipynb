{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting: A model performs well on training data but poorly on unseen data because it has learned noise and details specific to the training set.\n",
    "\n",
    "Consequences: Poor generalization, high variance.\n",
    "\n",
    "Mitigation: Regularization, reducing model complexity, adding more data, early stopping, dropout, cross-validation.\n",
    "\n",
    "Underfitting: A model performs poorly on both training and testing data because it is too simple to capture the underlying patterns.\n",
    "\n",
    "Consequences: Poor accuracy, high bias.\n",
    "Mitigation: Increase model complexity, reduce regularization, feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use regularization techniques like L1 (Lasso) or L2 (Ridge).\n",
    "\n",
    "Use simpler models or reduce model complexity.\n",
    "\n",
    "Increase training data.\n",
    "\n",
    "Apply data augmentation.\n",
    "\n",
    "Use dropout in neural networks.\n",
    "\n",
    "Use cross-validation to ensure generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting: A model fails to learn the patterns in the training data, leading to poor performance on both training and testing sets.\n",
    "\n",
    "Scenarios where it occurs:\n",
    "\n",
    "Model is too simple (e.g., linear model for non-linear data).\n",
    "\n",
    "Insufficient training (too few epochs).\n",
    "\n",
    "Poor feature selection or insufficient data preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias: Error due to overly simplistic assumptions; leads to underfitting.\n",
    "\n",
    "Variance: Error due to sensitivity to small fluctuations in training data; leads to overfitting.\n",
    "\n",
    "Tradeoff: Reducing bias increases variance, and reducing variance increases bias. An optimal tradeoff minimizes total error for good generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting detection:\n",
    "\n",
    "High accuracy on training but poor on validation/test sets.\n",
    "\n",
    "Large gap between training and testing errors.\n",
    "\n",
    "Underfitting detection:\n",
    "\n",
    "Poor performance on both training and testing sets.\n",
    "\n",
    "Techniques: Learning curves, validation error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias: Systematic error; high bias models are simple and underfit the data (e.g., linear regression on complex data).\n",
    "\n",
    "Variance: Sensitivity to training data; high variance models are complex and overfit the data (e.g., deep neural networks).\n",
    "\n",
    "Difference: High bias models lack flexibility, while high variance models are overly flexible and memorize data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: Techniques to prevent overfitting by adding a penalty to model complexity.\n",
    "\n",
    "Common techniques:\n",
    "\n",
    "L1 Regularization (Lasso): Adds absolute values of weights to the loss function; promotes sparsity.\n",
    "\n",
    "L2 Regularization (Ridge): Adds squared values of weights to the loss function; reduces weight magnitudes.\n",
    "\n",
    "Dropout: Randomly drops neurons during training.\n",
    "\n",
    "Early Stopping: Stops training when validation performance stops improving.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
