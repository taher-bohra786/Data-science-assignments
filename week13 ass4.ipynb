{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max scaling is a feature scaling technique that transforms data into a fixed range, typically [0,1] or [-1,1]. It ensures that all features contribute equally to the model by normalizing them based on the minimum and maximum values in the dataset.\n",
    "\n",
    "Formula - X - X min / X max - X min \n",
    "\n",
    "Example:\n",
    "Suppose we have a dataset of student exam scores:\n",
    "50,60,75,90,100\n",
    "Using Min-Max scaling in the range [0,1]:\n",
    "The scaled values are:\n",
    "0,0.2,0.5,0.8,1\n",
    "This transformation helps standardize different features before training a machine learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Unit Vector (Normalization) technique, also known as Vector Normalization, scales feature vectors so that they have a unit norm (magnitude of 1). It ensures that all feature values contribute equally by dividing each value by the Euclidean norm (L2 norm).\n",
    "\n",
    "Formula:\n",
    "\n",
    "X' = X / ||X||\n",
    "\n",
    "Difference from Min-Max Scaling:\n",
    "\n",
    "Min-Max Scaling transforms values to a fixed range, maintaining their relative differences.\n",
    "Unit Vector Scaling transforms values so they have a unit norm, making them comparable in magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a linear dimensionality reduction technique that transforms data into a new coordinate system, where the highest variance is captured along the principal components (PCs).\n",
    "\n",
    "How PCA works:\n",
    "\n",
    "Standardize the dataset (mean = 0, variance = 1).\n",
    "\n",
    "Compute the covariance matrix to understand feature relationships.\n",
    "\n",
    "Perform eigenvalue decomposition to find eigenvectors (principal components).\n",
    "\n",
    "Select the top k principal components that explain the most variance.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose we have height and weight data. These features are correlated. PCA will create a new axis (principal \n",
    "component) that captures the maximum variance, reducing redundancy. This helps when we want to reduce dimensions while retaining most of the information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship:\n",
    "\n",
    "Feature Selection chooses a subset of existing features.\n",
    "\n",
    "Feature Extraction creates new features by transforming existing ones, which is exactly what PCA does.\n",
    "\n",
    "How PCA is used for Feature Extraction:\n",
    "\n",
    "PCA projects data onto a new space where each principal component is a linear combination of the original features. Instead of selecting features, it creates new ones that retain most of the original dataset's variance.\n",
    "\n",
    "Example:\n",
    "If we have three features (height, weight, BMI) that are correlated, PCA can combine them into one or two principal components, reducing redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a dataset with price, rating, and delivery time, Min-Max Scaling helps normalize these features:\n",
    "\n",
    "Find Min and Max for each feature:\n",
    "\n",
    "Price: Min = $5, Max = $50\n",
    "\n",
    "Rating: Min = 1, Max = 5\n",
    "\n",
    "Delivery Time: Min = 10 min, Max = 60 min\n",
    "\n",
    "Apply Min-Max Scaling (0 to 1):\n",
    "\n",
    "Scaled Price = price - 5 / 50 - 5\n",
    "\n",
    "​Scaled Rating = \n",
    "Rating =  Rating−1 / 5 - 1\n",
    "​\n",
    " Scaled Delivery Time = \n",
    "Delivery Time = Delivery Time − 10 / 60 − 10\n",
    "​\n",
    " \n",
    "This ensures all features are within the same range and comparable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock price prediction datasets often have hundreds of financial indicators and market trends. Using PCA:\n",
    "\n",
    "Standardize features (e.g., revenue, profit margin, P/E ratio).\n",
    "Compute the covariance matrix to find correlated features.\n",
    "Find eigenvalues and eigenvectors, selecting k principal components that explain 95% variance.\n",
    "Transform data into the new PCA-reduced space, keeping only the most important information.\n",
    "This helps in reducing overfitting and computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -0.5789473684210527, -0.052631578947368474, 0.4736842105263157, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def min_max_scaling(data, new_min=-1, new_max=1):\n",
    "    old_min = min(data)\n",
    "    old_max = max(data)\n",
    "    \n",
    "    scaled_data = [\n",
    "        new_min + ((x - old_min) * (new_max - new_min)) / (old_max - old_min)\n",
    "        for x in data\n",
    "    ]\n",
    "    return scaled_data\n",
    "\n",
    "# Given dataset\n",
    "data = [1, 5, 10, 15, 20]\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaled_data = min_max_scaling(data)\n",
    "\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Standardize Data\n",
    "Convert height, weight, age, and blood pressure to z-scores (mean = 0, variance = 1).\n",
    "\n",
    "Step 2: Compute Covariance Matrix\n",
    "Analyze correlations:\n",
    "\n",
    "Height and weight are correlated.\n",
    "Age and blood pressure might be correlated.\n",
    "Gender is categorical (0 or 1).\n",
    "Step 3: Find Principal Components\n",
    "Eigenvalues reveal how much variance each component explains.\n",
    "\n",
    "Step 4: Choose Principal Components\n",
    "\n",
    "If top 2 PCs explain 95% of variance, retain them.\n",
    "Instead of 5 original features, we now have 2 transformed features capturing most information.\n",
    "This helps in reducing dimensionality while retaining key patterns in the data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
