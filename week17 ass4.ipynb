{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Q1. How does bagging reduce overfitting in decision trees?**  \n",
    "Bagging reduces overfitting by training multiple decision trees on different random subsets of the data and combining their predictions. This helps smooth out errors and reduces the variance of the model.\n",
    "\n",
    "#### **Q2. What are the advantages and disadvantages of using different types of base learners in bagging?**  \n",
    "- **Advantages**: Bagging works best with high-variance models like decision trees, making them more stable and reducing overfitting.  \n",
    "- **Disadvantages**: If the base model has low variance (e.g., linear regression), bagging may not provide much improvement.\n",
    "\n",
    "#### **Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?**  \n",
    "- If the base learner has **high variance** (e.g., deep decision trees), bagging helps by reducing variance.  \n",
    "- If the base learner has **high bias** (e.g., linear regression), bagging wonâ€™t help much because the model is already too simple.\n",
    "\n",
    "#### **Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?**  \n",
    "Yes, bagging can be used for both:  \n",
    "- **Classification**: Uses majority voting (most common class wins).  \n",
    "- **Regression**: Takes the average of predictions.\n",
    "\n",
    "#### **Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?**  \n",
    "A larger ensemble reduces variance, but after a certain point, adding more models gives little improvement. Usually, **100 to 500 models** are used in practice.\n",
    "\n",
    "#### **Q6. Can you provide an example of a real-world application of bagging in machine learning?**  \n",
    "Bagging is used in **fraud detection**, where models like Random Forest analyze financial transactions to detect suspicious activity while reducing overfitting to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
