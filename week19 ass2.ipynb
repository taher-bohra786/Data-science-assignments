{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Q1. What is hierarchical clustering, and how is it different from other clustering techniques?  \n",
    "**Hierarchical clustering** is a clustering technique that builds a hierarchy of clusters in a **tree-like structure** called a **dendrogram**.  \n",
    "\n",
    "**Differences from other clustering techniques:**  \n",
    " **No need to predefine \\( K \\)** (Unlike K-Means, which requires specifying the number of clusters).  \n",
    " **Produces a hierarchy** (Unlike K-Means, which produces flat partitions).  \n",
    " **Can handle arbitrary-shaped clusters** (Unlike K-Means, which assumes spherical clusters).  \n",
    " **More interpretable** than centroid-based methods.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief.**  \n",
    "1. **Agglomerative Hierarchical Clustering (Bottom-Up Approach):**  \n",
    "   - **Starts with each point as its own cluster.**  \n",
    "   - Merges the closest clusters iteratively until only one cluster remains.  \n",
    "   - **Most common approach** used in practice.  \n",
    "\n",
    "2. **Divisive Hierarchical Clustering (Top-Down Approach):**  \n",
    "   - **Starts with all points in a single cluster.**  \n",
    "   - Recursively splits clusters into smaller clusters.  \n",
    "   - Less commonly used due to its **higher computational cost**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the common distance metrics used?**  \n",
    "\n",
    " **Common Linkage Methods (Cluster Distance Measures):**  \n",
    "- **Single Linkage:** Distance between the closest points in two clusters.  \n",
    "- **Complete Linkage:** Distance between the farthest points in two clusters.  \n",
    "- **Average Linkage:** Average pairwise distance between all points in two clusters.  \n",
    "- **Centroid Linkage:** Distance between the centroids of two clusters.  \n",
    "- **Ward’s Method:** Minimizes the variance between clusters (often the best for compact clusters).  \n",
    "\n",
    " **Common Distance Metrics (Point Distance Measures):**  \n",
    "- **Euclidean Distance:** \\(\\sqrt{\\sum (x_i - y_i)^2}\\)  \n",
    "- **Manhattan Distance:** \\(\\sum |x_i - y_i|\\)  \n",
    "- **Cosine Similarity:** Measures angle between vectors (used for text data).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some common methods used for this purpose?**  \n",
    "1. **Dendrogram Cut:**  \n",
    "   - Cut the **dendrogram** at the point where the largest jump in distance occurs.  \n",
    "\n",
    "2. **Elbow Method:**  \n",
    "   - Plot **intra-cluster variance** vs. number of clusters and find the \"elbow\" point.  \n",
    "\n",
    "3. **Silhouette Score:**  \n",
    "   - Measures how well each point fits within its cluster.  \n",
    "\n",
    "4. **Gap Statistic:**  \n",
    "   - Compares clustering results with random clustering.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?**  \n",
    " A **dendrogram** is a **tree-like visualization** that shows how clusters are formed at each step.  \n",
    "\n",
    " Helps determine **the number of clusters** by **cutting the tree at a threshold**.  \n",
    " Shows how **closely data points are related** based on linkage distance.  \n",
    " Useful for **detecting hierarchical relationships** in data.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the distance metrics different for each type of data?**  \n",
    "\n",
    " **Yes, hierarchical clustering can be used for both numerical and categorical data.**  \n",
    "\n",
    " **Distance Metrics for Numerical Data:**  \n",
    "- **Euclidean Distance**  \n",
    "- **Manhattan Distance**  \n",
    "- **Mahalanobis Distance**  \n",
    "\n",
    " **Distance Metrics for Categorical Data:**  \n",
    "- **Hamming Distance:** Measures the number of different categorical attributes.  \n",
    "- **Jaccard Similarity:** Measures similarity between categorical sets.  \n",
    "- **Gower’s Distance:** Handles mixed numerical and categorical data.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?**  \n",
    "\n",
    " **Anomalies (Outliers) appear as small clusters that are distant from others.**  \n",
    "\n",
    " **Steps to detect outliers using hierarchical clustering:**  \n",
    "1. Perform hierarchical clustering on the dataset.  \n",
    "2. Generate a **dendrogram** and identify clusters that are **far away from the main groups**.  \n",
    "3. Use **distance thresholding** to detect outlier clusters.  \n",
    "\n",
    " **Alternative Approach:**  \n",
    "- Use **Silhouette Scores** to identify poorly clustered points (potential outliers).  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
