{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Q1.  \n",
    "Ensemble techniques combine multiple machine learning models to improve overall performance by reducing variance, bias, or both. Common ensemble methods include **bagging, boosting, and stacking**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Q2.**  \n",
    "Ensemble techniques are used because they:  \n",
    "- Improve prediction accuracy by **combining multiple models**.  \n",
    "- Reduce **overfitting** by averaging out individual model errors.  \n",
    "- Increase **model stability and robustness**.  \n",
    "- Work well when individual models have **complementary strengths**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Q3.**  \n",
    "**Bagging (Bootstrap Aggregating)** is an ensemble method that trains multiple models on different **random subsets** of the dataset (using bootstrap sampling) and averages their predictions.  \n",
    "- Example: **Random Forest** (bagging applied to decision trees).  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Q4.   \n",
    "**Boosting** is an ensemble method that trains models **sequentially**, where each new model focuses on correcting the errors of the previous models.  \n",
    "- Example: **AdaBoost, Gradient Boosting, XGBoost, LightGBM**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Q5.**  \n",
    "- **Higher Accuracy**: Combines multiple models to achieve better performance.  \n",
    "- **Reduces Overfitting**: Bagging reduces variance, while boosting reduces bias.  \n",
    "- **Handles Complex Data Better**: Works well for non-linear patterns.  \n",
    "- **Robustness**: Less sensitive to noise in data.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Q6.**  \n",
    "Not always. While ensembles often improve performance, they:  \n",
    "- Increase **computational cost**.  \n",
    "- May **overfit** if the base models are too complex.  \n",
    "- Require **more data** for training to be effective.  \n",
    "In some cases, a **single well-tuned model** can outperform an ensemble.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Q7.**  \n",
    "Bootstrap estimates the confidence interval by:  \n",
    "1. Resampling the dataset **with replacement** multiple times (e.g., 1000 times).  \n",
    "2. Computing the statistic (e.g., mean) for each resampled dataset.  \n",
    "3. Taking the **percentile range** (e.g., 2.5% to 97.5%) of these estimates as the **confidence interval**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Q8.**  \n",
    "**Bootstrap** is a resampling method used to estimate statistics and confidence intervals.  \n",
    "\n",
    "**Steps:**  \n",
    "1. **Draw multiple random samples** (with replacement) from the original dataset.  \n",
    "2. **Compute the statistic** (e.g., mean, median) for each sample.  \n",
    "3. **Repeat the process** many times (e.g., 1000 iterations).  \n",
    "4. **Use percentiles** of the sampled statistics to estimate confidence intervals.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q9.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(14.478577387887631), np.float64(15.536145295992682))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "sample_mean = 15  \n",
    "sample_std = 2   \n",
    "n = 50          \n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Generate bootstrap samples\n",
    "bootstrap_means = np.random.normal(loc=sample_mean, scale=sample_std/np.sqrt(n), size=num_bootstrap_samples)\n",
    "\n",
    "# Compute 95% confidence interval (2.5th and 97.5th percentiles)\n",
    "ci_lower, ci_upper = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "(ci_lower, ci_upper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
