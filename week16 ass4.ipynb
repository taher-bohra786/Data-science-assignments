{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1:\n",
    "Polynomial functions are used in polynomial kernels, which are a type of kernel function in machine learning. Kernel functions transform the input space into a higher-dimensional space, allowing Support Vector Machines (SVMs) to classify non-linearly separable data. The polynomial kernel is given by:\n",
    "\n",
    "ùêæ\n",
    "(\n",
    "ùë•\n",
    ",\n",
    "ùë¶\n",
    ")\n",
    "=\n",
    "(\n",
    "ùë•\n",
    "‚ãÖ\n",
    "ùë¶\n",
    "+\n",
    "ùëê\n",
    ")\n",
    "ùëë\n",
    "K(x,y)=(x‚ãÖy+c) \n",
    "d\n",
    " \n",
    "where \n",
    "ùëë\n",
    "d is the polynomial degree, and \n",
    "ùëê\n",
    "c is a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate dataset with proper feature distribution\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_informative=3, \n",
    "                           n_redundant=1, n_repeated=0, random_state=42)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM with polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1.0)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3:\n",
    "Increasing the epsilon (Œµ) value in Support Vector Regression (SVR) increases the tolerance for prediction errors, leading to fewer support vectors because more data points fall within the Œµ-margin and are ignored. This reduces model complexity but may also decrease accuracy.\n",
    "\n",
    "Q4:\n",
    "Kernel function: Determines the transformation of the input space. Examples:\n",
    "Linear: For simple, linearly separable data.\n",
    "Polynomial: For complex, non-linear patterns.\n",
    "RBF (Radial Basis Function): For highly non-linear data.\n",
    "C parameter (Regularization):\n",
    "Higher C ‚Üí Less margin, better fit but may overfit.\n",
    "Lower C ‚Üí Larger margin, better generalization.\n",
    "Epsilon (Œµ) (SVR tolerance):\n",
    "Higher Œµ ‚Üí Fewer support vectors, simpler model.\n",
    "Lower Œµ ‚Üí More support vectors, more precise model.\n",
    "Gamma (Œ≥) (Kernel coefficient for RBF and Polynomial):\n",
    "Higher Œ≥ ‚Üí More complex decision boundary, can overfit.\n",
    "Lower Œ≥ ‚Üí Simpler model, may underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        43\n",
      "           1       0.83      1.00      0.90        71\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.91      0.83      0.85       114\n",
      "weighted avg       0.89      0.87      0.86       114\n",
      "\n",
      "Model saved as svc_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load dataset (Example: Breast Cancer dataset)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data (Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVC classifier\n",
    "svc = SVC(kernel='poly', degree=3, C=1.0)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'degree': [2, 3, 4], 'kernel': ['poly']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Train best model on entire dataset\n",
    "best_svc = grid_search.best_estimator_\n",
    "best_svc.fit(X, y)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_svc, \"svc_model.pkl\")\n",
    "print(\"Model saved as svc_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
