{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.**  \n",
    "Linear regression predicts continuous values, while logistic regression predicts probabilities for categorical outcomes. Logistic regression is better for classification tasks, such as spam detection (spam or not spam).  \n",
    "\n",
    "**Q2.**  \n",
    "Logistic regression uses the **log-loss (binary cross-entropy)** as the cost function. It is optimized using **gradient descent** or similar optimization algorithms.  \n",
    "\n",
    "**Q3.**  \n",
    "Regularization (L1/L2) adds a penalty term to the cost function to reduce overfitting. L1 (Lasso) helps with feature selection, while L2 (Ridge) prevents large coefficients.  \n",
    "\n",
    "**Q4.**  \n",
    "The **ROC curve** plots the **True Positive Rate (TPR) vs. False Positive Rate (FPR)** at different thresholds. AUC (Area Under Curve) measures model performance—closer to 1 is better.  \n",
    "\n",
    "**Q5.**  \n",
    "Common feature selection techniques:  \n",
    "- **L1 Regularization (Lasso):** Shrinks coefficients to zero.  \n",
    "- **Mutual Information:** Measures dependency between features and target.  \n",
    "- **Recursive Feature Elimination (RFE):** Iteratively removes less important features.  \n",
    "These improve performance by reducing noise and overfitting.  \n",
    "\n",
    "**Q6.**  \n",
    "Handling imbalanced datasets:  \n",
    "- **Resampling (Oversampling/Undersampling)**  \n",
    "- **Using class weights (e.g., in sklearn’s `class_weight='balanced'`)**  \n",
    "- **Synthetic data generation (SMOTE)**  \n",
    "- **Threshold tuning based on precision-recall balance**  \n",
    "\n",
    "**Q7.**  \n",
    "Common challenges & solutions:  \n",
    "- **Multicollinearity:** Use **VIF (Variance Inflation Factor)**, remove correlated features, or apply **PCA**.  \n",
    "- **Overfitting:** Use **regularization (L1/L2)** or reduce feature count.  \n",
    "- **Poor Convergence:** Scale features, adjust learning rate, or use different solvers (e.g., `lbfgs`, `saga`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
