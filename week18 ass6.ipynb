{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach?**  \n",
    "- **Eigenvalues (\\(\\lambda\\))** and **Eigenvectors (\\(v\\))** of a square matrix \\( A \\) satisfy the equation:  \n",
    "  \\[\n",
    "  A v = \\lambda v\n",
    "  \\]  \n",
    "  where:\n",
    "  - \\( v \\) is a nonzero vector (eigenvector).\n",
    "  - \\( \\lambda \\) is a scalar (eigenvalue).\n",
    "\n",
    "- **Eigen-Decomposition** expresses \\( A \\) as:  \n",
    "  \\[\n",
    "  A = V \\Lambda V^{-1}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\( V \\) contains eigenvectors as columns.\n",
    "  - \\( \\Lambda \\) is a diagonal matrix of eigenvalues.\n",
    "\n",
    "**Example:**  \n",
    "For matrix \\( A \\):\n",
    "\\[\n",
    "A = \\begin{bmatrix} 4 & -2 \\\\ 1 & 1 \\end{bmatrix}\n",
    "\\]\n",
    "Solving \\( \\det(A - \\lambda I) = 0 \\), we get eigenvalues \\( \\lambda_1 = 3, \\lambda_2 = 2 \\) and corresponding eigenvectors.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. What is eigen decomposition and what is its significance in linear algebra?**  \n",
    "Eigen-Decomposition is the process of breaking a matrix into its eigenvectors and eigenvalues.  \n",
    "\n",
    "**Significance:**  \n",
    "- **Dimensionality reduction (e.g., PCA).**  \n",
    "- **Solving differential equations.**  \n",
    "- **Understanding linear transformations.**  \n",
    "- **Fast computation of matrix powers and exponentials.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof.**  \n",
    "A matrix \\( A \\) is **diagonalizable** if it has **linearly independent eigenvectors** (i.e., the number of independent eigenvectors equals the matrix size \\( n \\)).  \n",
    "\n",
    "**Condition:**  \n",
    "- The matrix must have **\\( n \\) linearly independent eigenvectors**.  \n",
    "- A sufficient condition: If \\( A \\) has **\\( n \\) distinct eigenvalues**, it is always diagonalizable.  \n",
    "\n",
    "**Proof (sketch):**  \n",
    "If \\( A \\) has \\( n \\) independent eigenvectors, then:  \n",
    "\\[\n",
    "A = V \\Lambda V^{-1}\n",
    "\\]\n",
    "where \\( V \\) contains eigenvectors and \\( \\Lambda \\) contains eigenvalues.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix?**  \n",
    "**Spectral Theorem:**  \n",
    "A **symmetric matrix** \\( A \\) (i.e., \\( A = A^T \\)) is always diagonalizable using **orthogonal eigenvectors**.  \n",
    "\n",
    "**Significance:**  \n",
    "- It guarantees that real symmetric matrices have **real eigenvalues** and **orthogonal eigenvectors**.  \n",
    "- Used in **PCA**, **SVD**, and **Quantum Mechanics**.  \n",
    "\n",
    "**Example:**  \n",
    "For a symmetric matrix:\n",
    "\\[\n",
    "A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n",
    "\\]\n",
    "It has **real eigenvalues** and **orthogonal eigenvectors**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q5. How do you find the eigenvalues of a matrix and what do they represent?**  \n",
    "1. Solve the **characteristic equation**:  \n",
    "   \\[\n",
    "   \\det(A - \\lambda I) = 0\n",
    "   \\]\n",
    "2. The roots of this equation are the **eigenvalues**.  \n",
    "\n",
    "**Interpretation:**  \n",
    "- Eigenvalues represent **scaling factors** in the direction of eigenvectors.  \n",
    "- If an eigenvalue is **positive**, the transformation preserves direction.  \n",
    "- If **negative**, the direction is flipped.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q6. What are eigenvectors and how are they related to eigenvalues?**  \n",
    "- Eigenvectors are **directions** along which a transformation acts as simple scaling.  \n",
    "- They correspond to **eigenvalues**, which determine the magnitude of scaling.  \n",
    "\n",
    "For matrix \\( A \\), if \\( v \\) is an eigenvector:\n",
    "\\[\n",
    "A v = \\lambda v\n",
    "\\]\n",
    "then \\( \\lambda \\) tells how much \\( v \\) is stretched or shrunk.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?**  \n",
    "- **Eigenvectors** are the directions in which a transformation does not rotate the vector.  \n",
    "- **Eigenvalues** tell how much the vector is stretched or compressed.  \n",
    "\n",
    "**Example:**  \n",
    "For **2D rotation matrices**, eigenvectors show **fixed directions** that remain unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q8. What are some real-world applications of eigen decomposition?**  \n",
    " **PCA (Principal Component Analysis)** – Reduces dimensionality while preserving variance.  \n",
    " **Vibration analysis** – Identifies natural frequencies in structures.  \n",
    " **Quantum mechanics** – Used to study quantum states and energy levels.  \n",
    " **Google PageRank** – Eigenvectors determine webpage rankings.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?**  \n",
    "- A matrix has **unique eigenvalues**, but eigenvectors can be **scaled**.  \n",
    "- If eigenvalues are **repeated**, eigenvectors might not be unique.  \n",
    "- Some matrices (e.g., defective matrices) **lack a full set of linearly independent eigenvectors**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning?**  \n",
    "Three key applications:  \n",
    "1. **PCA (Principal Component Analysis)** – Uses eigenvectors of the covariance matrix for feature reduction.  \n",
    "2. **Spectral Clustering** – Uses eigenvalues of graph Laplacian matrices for clustering.  \n",
    "3. **Latent Semantic Analysis (LSA)** – Applies eigen-decomposition to text data for topic modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
